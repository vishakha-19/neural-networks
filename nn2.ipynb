{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = pd.read_csv('forestfires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      "month            517 non-null object\n",
      "day              517 non-null object\n",
      "FFMC             517 non-null float64\n",
      "DMC              517 non-null float64\n",
      "DC               517 non-null float64\n",
      "ISI              517 non-null float64\n",
      "temp             517 non-null float64\n",
      "RH               517 non-null int64\n",
      "wind             517 non-null float64\n",
      "rain             517 non-null float64\n",
      "area             517 non-null float64\n",
      "dayfri           517 non-null int64\n",
      "daymon           517 non-null int64\n",
      "daysat           517 non-null int64\n",
      "daysun           517 non-null int64\n",
      "daythu           517 non-null int64\n",
      "daytue           517 non-null int64\n",
      "daywed           517 non-null int64\n",
      "monthapr         517 non-null int64\n",
      "monthaug         517 non-null int64\n",
      "monthdec         517 non-null int64\n",
      "monthfeb         517 non-null int64\n",
      "monthjan         517 non-null int64\n",
      "monthjul         517 non-null int64\n",
      "monthjun         517 non-null int64\n",
      "monthmar         517 non-null int64\n",
      "monthmay         517 non-null int64\n",
      "monthnov         517 non-null int64\n",
      "monthoct         517 non-null int64\n",
      "monthsep         517 non-null int64\n",
      "size_category    517 non-null object\n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "forest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=forest.drop(['month','day'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "forest.size_category.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lable_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest['size_category'] = lable_encoder.fit_transform(forest.size_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  dayfri  ...  monthfeb  \\\n",
       "0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0       1  ...         0   \n",
       "1  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0       0  ...         0   \n",
       "2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0       0  ...         0   \n",
       "3  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0       1  ...         0   \n",
       "4  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0       0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0              1  \n",
       "1         0              1  \n",
       "2         0              1  \n",
       "3         0              1  \n",
       "4         0              1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 29)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_array= forest.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = f_array[:,0:28]\n",
    "Y = f_array[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(X)\n",
    "X_standardized = a.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-1.754024e-15</td>\n",
       "      <td>3.070830e-16</td>\n",
       "      <td>7.387171e-17</td>\n",
       "      <td>-3.865380e-17</td>\n",
       "      <td>2.005703e-16</td>\n",
       "      <td>3.362881e-16</td>\n",
       "      <td>-2.676776e-16</td>\n",
       "      <td>-2.841054e-16</td>\n",
       "      <td>-1.274502e-16</td>\n",
       "      <td>4.874674e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-1.304582e+01</td>\n",
       "      <td>-1.715608e+00</td>\n",
       "      <td>-2.179108e+00</td>\n",
       "      <td>-1.980578e+00</td>\n",
       "      <td>-2.876943e+00</td>\n",
       "      <td>-1.796637e+00</td>\n",
       "      <td>-2.021098e+00</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-8.063453e-02</td>\n",
       "      <td>-6.606652e-01</td>\n",
       "      <td>-4.448281e-01</td>\n",
       "      <td>-5.535954e-01</td>\n",
       "      <td>-5.842379e-01</td>\n",
       "      <td>-6.924563e-01</td>\n",
       "      <td>-7.361236e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-2.020198e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.732292e-01</td>\n",
       "      <td>-4.020255e-02</td>\n",
       "      <td>4.691190e-01</td>\n",
       "      <td>-1.364774e-01</td>\n",
       "      <td>7.082076e-02</td>\n",
       "      <td>-1.403660e-01</td>\n",
       "      <td>-9.833712e-03</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-1.938429e-01</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.089598e-01</td>\n",
       "      <td>4.927389e-01</td>\n",
       "      <td>6.696628e-01</td>\n",
       "      <td>3.904086e-01</td>\n",
       "      <td>6.741643e-01</td>\n",
       "      <td>5.344111e-01</td>\n",
       "      <td>4.929823e-01</td>\n",
       "      <td>-7.326831e-02</td>\n",
       "      <td>-9.870852e-02</td>\n",
       "      <td>-4.435755e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.007353e+00</td>\n",
       "      <td>2.819865e+00</td>\n",
       "      <td>1.261610e+00</td>\n",
       "      <td>1.033538e+01</td>\n",
       "      <td>2.484195e+00</td>\n",
       "      <td>3.417549e+00</td>\n",
       "      <td>3.007063e+00</td>\n",
       "      <td>2.157228e+01</td>\n",
       "      <td>1.695111e+01</td>\n",
       "      <td>2.254407e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -1.754024e-15  3.070830e-16  7.387171e-17 -3.865380e-17  2.005703e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.304582e+01 -1.715608e+00 -2.179108e+00 -1.980578e+00 -2.876943e+00   \n",
       "25%   -8.063453e-02 -6.606652e-01 -4.448281e-01 -5.535954e-01 -5.842379e-01   \n",
       "50%    1.732292e-01 -4.020255e-02  4.691190e-01 -1.364774e-01  7.082076e-02   \n",
       "75%    4.089598e-01  4.927389e-01  6.696628e-01  3.904086e-01  6.741643e-01   \n",
       "max    1.007353e+00  2.819865e+00  1.261610e+00  1.033538e+01  2.484195e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   3.362881e-16 -2.676776e-16 -2.841054e-16 -1.274502e-16  4.874674e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.796637e+00 -2.021098e+00 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "25%   -6.924563e-01 -7.361236e-01 -7.326831e-02 -2.020198e-01 -4.435755e-01   \n",
       "50%   -1.403660e-01 -9.833712e-03 -7.326831e-02 -1.938429e-01 -4.435755e-01   \n",
       "75%    5.344111e-01  4.929823e-01 -7.326831e-02 -9.870852e-02 -4.435755e-01   \n",
       "max    3.417549e+00  3.007063e+00  2.157228e+01  1.695111e+01  2.254407e+00   \n",
       "\n",
       "       ...            18            19            20            21  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 22            23            24            25            26  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 27  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 28,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = [10,20]\n",
    "epochs = [10,30]\n",
    "learning_rate = [0.001,0.1]\n",
    "dropout_rate = [0.0,0.1]\n",
    "activation_function = ['softmax','relu']\n",
    "init = ['normal']\n",
    "neuron1 = [4,8]\n",
    "neuron2 = [2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "[CV 1/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=  38.0s\n",
      "[CV 2/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.476 total time=   4.0s\n",
      "[CV 4/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   4.1s\n",
      "[CV 5/5; 1/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 1/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.8s\n",
      "[CV 1/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   4.3s\n",
      "[CV 2/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   4.0s\n",
      "[CV 4/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.8s\n",
      "[CV 5/5; 2/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 2/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   4.0s\n",
      "[CV 1/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   4.1s\n",
      "[CV 3/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   4.1s\n",
      "[CV 4/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.9s\n",
      "[CV 5/5; 3/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 3/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   4.4s\n",
      "[CV 1/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   3.9s\n",
      "[CV 3/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   4.1s\n",
      "[CV 4/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   4.1s\n",
      "[CV 5/5; 4/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 4/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   4.0s\n",
      "[CV 1/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.817 total time=   3.8s\n",
      "[CV 3/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.8s\n",
      "[CV 4/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.748 total time=   4.3s\n",
      "[CV 5/5; 5/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 5/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.660 total time=   3.9s\n",
      "[CV 1/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.846 total time=   3.9s\n",
      "[CV 2/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.788 total time=   3.9s\n",
      "[CV 3/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.728 total time=   4.0s\n",
      "[CV 4/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.757 total time=   4.2s\n",
      "[CV 5/5; 6/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 6/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.816 total time=   3.8s\n",
      "[CV 1/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.865 total time=   3.9s\n",
      "[CV 2/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.788 total time=   3.7s\n",
      "[CV 3/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   4.5s\n",
      "[CV 4/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   3.9s\n",
      "[CV 5/5; 7/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 7/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   4.1s\n",
      "[CV 1/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.721 total time=   3.9s\n",
      "[CV 3/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   3.8s\n",
      "[CV 4/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   3.9s\n",
      "[CV 5/5; 8/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 8/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.738 total time=   3.8s\n",
      "[CV 1/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   5.0s\n",
      "[CV 2/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   5.2s\n",
      "[CV 3/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   6.4s\n",
      "[CV 4/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   5.7s\n",
      "[CV 5/5; 9/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 9/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   5.4s\n",
      "[CV 1/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   5.3s\n",
      "[CV 2/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   5.5s\n",
      "[CV 3/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   5.4s\n",
      "[CV 4/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   5.8s\n",
      "[CV 5/5; 10/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 10/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   5.3s\n",
      "[CV 1/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   5.1s\n",
      "[CV 2/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.8s\n",
      "[CV 3/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   3.8s\n",
      "[CV 4/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.7s\n",
      "[CV 5/5; 11/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 11/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.728 total time=   3.4s\n",
      "[CV 1/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   3.1s\n",
      "[CV 3/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   3.0s\n",
      "[CV 4/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   3.8s\n",
      "[CV 5/5; 12/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 12/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   2.6s\n",
      "[CV 1/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.981 total time=   5.0s\n",
      "[CV 2/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.788 total time=   4.4s\n",
      "[CV 3/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   4.1s\n",
      "[CV 4/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   4.3s\n",
      "[CV 5/5; 13/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 13/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.806 total time=   3.8s\n",
      "[CV 1/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   3.5s\n",
      "[CV 2/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.827 total time=   3.6s\n",
      "[CV 3/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.728 total time=   4.2s\n",
      "[CV 4/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.777 total time=   3.7s\n",
      "[CV 5/5; 14/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 14/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   4.3s\n",
      "[CV 1/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.942 total time=   3.9s\n",
      "[CV 2/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.760 total time=   4.5s\n",
      "[CV 3/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.621 total time=   3.3s\n",
      "[CV 4/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.718 total time=   2.7s\n",
      "[CV 5/5; 15/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 15/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.757 total time=   3.6s\n",
      "[CV 1/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.981 total time=   4.3s\n",
      "[CV 2/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.779 total time=   4.6s\n",
      "[CV 3/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.573 total time=   3.7s\n",
      "[CV 4/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.777 total time=   3.6s\n",
      "[CV 5/5; 16/128] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 16/128] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.796 total time=   3.8s\n",
      "[CV 1/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   2.7s\n",
      "[CV 2/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   2.3s\n",
      "[CV 3/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   2.3s\n",
      "[CV 4/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.3s\n",
      "[CV 5/5; 17/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 17/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   2.6s\n",
      "[CV 1/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   2.9s\n",
      "[CV 3/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   2.7s\n",
      "[CV 5/5; 18/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 18/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.301 total time=   2.6s\n",
      "[CV 1/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.6s\n",
      "[CV 3/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   2.9s\n",
      "[CV 5/5; 19/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 19/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   1.1s\n",
      "[CV 5/5; 20/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 20/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.990 total time=   1.1s\n",
      "[CV 2/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.644 total time=   1.1s\n",
      "[CV 3/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.1s\n",
      "[CV 4/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   1.2s\n",
      "[CV 5/5; 21/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 21/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   1.4s\n",
      "[CV 1/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.904 total time=   1.2s\n",
      "[CV 2/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   1.1s\n",
      "[CV 3/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   1.2s\n",
      "[CV 4/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.650 total time=   1.2s\n",
      "[CV 5/5; 22/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 22/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.660 total time=   1.2s\n",
      "[CV 1/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.933 total time=   1.2s\n",
      "[CV 2/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.731 total time=   1.2s\n",
      "[CV 3/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.553 total time=   1.3s\n",
      "[CV 4/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.689 total time=   1.2s\n",
      "[CV 5/5; 23/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 23/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   1.2s\n",
      "[CV 1/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   1.4s\n",
      "[CV 2/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.740 total time=   1.3s\n",
      "[CV 3/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   1.2s\n",
      "[CV 5/5; 24/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 24/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.631 total time=   1.2s\n",
      "[CV 1/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 25/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 25/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 26/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 26/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   1.7s\n",
      "[CV 4/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   1.7s\n",
      "[CV 5/5; 27/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 27/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   1.9s\n",
      "[CV 2/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   1.8s\n",
      "[CV 5/5; 28/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 28/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   1.7s\n",
      "[CV 3/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.6s\n",
      "[CV 4/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   1.6s\n",
      "[CV 5/5; 29/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 29/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   1.7s\n",
      "[CV 1/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.952 total time=   1.7s\n",
      "[CV 2/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.788 total time=   1.7s\n",
      "[CV 3/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.670 total time=   1.9s\n",
      "[CV 4/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   1.6s\n",
      "[CV 5/5; 30/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 30/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.7s\n",
      "[CV 1/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   3.7s\n",
      "[CV 3/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.631 total time=   4.2s\n",
      "[CV 4/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.738 total time=   4.7s\n",
      "[CV 5/5; 31/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 31/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   4.1s\n",
      "[CV 1/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.913 total time=   4.5s\n",
      "[CV 2/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   5.1s\n",
      "[CV 3/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   4.4s\n",
      "[CV 4/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   4.6s\n",
      "[CV 5/5; 32/128] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 32/128] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.757 total time=   3.3s\n",
      "[CV 1/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.250 total time=   2.9s\n",
      "[CV 3/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.476 total time=   1.6s\n",
      "[CV 4/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 33/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 33/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   2.8s\n",
      "[CV 1/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   2.8s\n",
      "[CV 2/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   2.5s\n",
      "[CV 3/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   2.9s\n",
      "[CV 5/5; 34/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 34/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   2.8s\n",
      "[CV 1/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   2.7s\n",
      "[CV 3/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.5s\n",
      "[CV 5/5; 35/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 35/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   2.5s\n",
      "[CV 1/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   2.1s\n",
      "[CV 2/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   2.9s\n",
      "[CV 3/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.320 total time=   1.6s\n",
      "[CV 5/5; 36/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 36/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   2.7s\n",
      "[CV 1/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.990 total time=   3.0s\n",
      "[CV 2/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.779 total time=   2.9s\n",
      "[CV 3/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.796 total time=   2.9s\n",
      "[CV 4/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   2.8s\n",
      "[CV 5/5; 37/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 37/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.786 total time=   2.4s\n",
      "[CV 1/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.962 total time=   2.8s\n",
      "[CV 2/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.808 total time=   2.9s\n",
      "[CV 3/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   2.9s\n",
      "[CV 4/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   3.0s\n",
      "[CV 5/5; 38/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 38/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.796 total time=   3.0s\n",
      "[CV 1/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   2.8s\n",
      "[CV 2/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.827 total time=   2.4s\n",
      "[CV 3/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.573 total time=   1.9s\n",
      "[CV 4/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.709 total time=   2.6s\n",
      "[CV 5/5; 39/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 39/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   2.2s\n",
      "[CV 1/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.885 total time=   2.6s\n",
      "[CV 2/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   2.9s\n",
      "[CV 3/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.621 total time=   2.9s\n",
      "[CV 4/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   2.7s\n",
      "[CV 5/5; 40/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 40/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.621 total time=   2.8s\n",
      "[CV 1/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.3s\n",
      "[CV 5/5; 41/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 41/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.2s\n",
      "[CV 1/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   2.7s\n",
      "[CV 2/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   2.4s\n",
      "[CV 3/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.6s\n",
      "[CV 5/5; 42/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 42/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   3.6s\n",
      "[CV 1/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   4.1s\n",
      "[CV 3/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.5s\n",
      "[CV 5/5; 43/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 43/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   3.7s\n",
      "[CV 1/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.3s\n",
      "[CV 5/5; 44/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 44/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   3.6s\n",
      "[CV 1/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.952 total time=   3.5s\n",
      "[CV 2/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.817 total time=   3.3s\n",
      "[CV 3/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.874 total time=   3.4s\n",
      "[CV 4/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.893 total time=   3.5s\n",
      "[CV 5/5; 45/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 45/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.825 total time=   2.8s\n",
      "[CV 1/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.990 total time=   2.6s\n",
      "[CV 2/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   3.2s\n",
      "[CV 3/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.718 total time=   3.5s\n",
      "[CV 4/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.893 total time=   3.7s\n",
      "[CV 5/5; 46/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 46/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   4.0s\n",
      "[CV 1/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.962 total time=   3.5s\n",
      "[CV 2/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.769 total time=   3.4s\n",
      "[CV 3/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.621 total time=   3.0s\n",
      "[CV 4/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   3.0s\n",
      "[CV 5/5; 47/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 47/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.796 total time=   3.7s\n",
      "[CV 1/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.981 total time=   3.3s\n",
      "[CV 2/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.788 total time=   3.0s\n",
      "[CV 3/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   3.5s\n",
      "[CV 4/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.767 total time=   4.1s\n",
      "[CV 5/5; 48/128] START activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 48/128] END activation_function=softmax, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.816 total time=   3.3s\n",
      "[CV 1/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   2.9s\n",
      "[CV 2/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   2.5s\n",
      "[CV 3/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.320 total time=   2.6s\n",
      "[CV 5/5; 49/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 49/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   2.9s\n",
      "[CV 1/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.000 total time=   2.6s\n",
      "[CV 2/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   2.8s\n",
      "[CV 3/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.5s\n",
      "[CV 5/5; 50/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 50/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   3.0s\n",
      "[CV 1/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.1s\n",
      "[CV 3/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.0s\n",
      "[CV 5/5; 51/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 51/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.301 total time=   3.1s\n",
      "[CV 1/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   3.6s\n",
      "[CV 3/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   3.1s\n",
      "[CV 4/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.8s\n",
      "[CV 5/5; 52/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 52/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   2.2s\n",
      "[CV 1/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.962 total time=   1.9s\n",
      "[CV 2/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.808 total time=   3.1s\n",
      "[CV 3/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.709 total time=   3.1s\n",
      "[CV 4/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.738 total time=   2.8s\n",
      "[CV 5/5; 53/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 53/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.0s\n",
      "[CV 1/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.942 total time=   3.5s\n",
      "[CV 2/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.769 total time=   3.1s\n",
      "[CV 3/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.796 total time=   2.3s\n",
      "[CV 4/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   3.2s\n",
      "[CV 5/5; 54/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 54/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.612 total time=   1.6s\n",
      "[CV 1/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.702 total time=   1.4s\n",
      "[CV 2/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   2.3s\n",
      "[CV 3/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.709 total time=   2.8s\n",
      "[CV 4/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.641 total time=   3.0s\n",
      "[CV 5/5; 55/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 55/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.786 total time=   3.3s\n",
      "[CV 1/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.981 total time=   3.1s\n",
      "[CV 2/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.760 total time=   2.7s\n",
      "[CV 3/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.631 total time=   2.3s\n",
      "[CV 4/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   2.7s\n",
      "[CV 5/5; 56/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 56/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   2.0s\n",
      "[CV 1/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.8s\n",
      "[CV 3/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   4.3s\n",
      "[CV 4/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.2s\n",
      "[CV 5/5; 57/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 57/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.7s\n",
      "[CV 1/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.1s\n",
      "[CV 3/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.9s\n",
      "[CV 5/5; 58/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 58/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   3.5s\n",
      "[CV 1/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   4.0s\n",
      "[CV 4/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.8s\n",
      "[CV 5/5; 59/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 59/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   3.4s\n",
      "[CV 1/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.0s\n",
      "[CV 5/5; 60/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 60/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   3.4s\n",
      "[CV 1/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.904 total time=   4.0s\n",
      "[CV 2/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   3.7s\n",
      "[CV 3/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.4s\n",
      "[CV 4/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.757 total time=   3.6s\n",
      "[CV 5/5; 61/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 61/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.816 total time=   3.9s\n",
      "[CV 1/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.894 total time=   3.3s\n",
      "[CV 2/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.837 total time=   3.7s\n",
      "[CV 3/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.786 total time=   3.4s\n",
      "[CV 4/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   2.6s\n",
      "[CV 5/5; 62/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 62/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   3.2s\n",
      "[CV 1/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.990 total time=   3.8s\n",
      "[CV 2/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.808 total time=   3.8s\n",
      "[CV 3/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.738 total time=   3.8s\n",
      "[CV 4/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.748 total time=   3.0s\n",
      "[CV 5/5; 63/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 63/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.689 total time=   3.4s\n",
      "[CV 1/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.971 total time=   3.3s\n",
      "[CV 2/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   3.3s\n",
      "[CV 3/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.709 total time=   3.8s\n",
      "[CV 4/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.728 total time=   2.6s\n",
      "[CV 5/5; 64/128] START activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 64/128] END activation_function=softmax, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.835 total time=   3.3s\n",
      "[CV 1/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.2s\n",
      "[CV 5/5; 65/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 65/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.2s\n",
      "[CV 1/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.0s\n",
      "[CV 3/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.1s\n",
      "[CV 5/5; 66/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 66/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   3.3s\n",
      "[CV 1/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.3s\n",
      "[CV 3/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   2.9s\n",
      "[CV 5/5; 67/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 67/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   3.6s\n",
      "[CV 1/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.971 total time=   3.4s\n",
      "[CV 2/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   3.3s\n",
      "[CV 3/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.612 total time=   3.3s\n",
      "[CV 4/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   3.2s\n",
      "[CV 5/5; 68/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 68/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   3.3s\n",
      "[CV 1/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.885 total time=   3.3s\n",
      "[CV 3/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   3.3s\n",
      "[CV 5/5; 69/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 69/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   1.8s\n",
      "[CV 1/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.817 total time=   3.0s\n",
      "[CV 2/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   3.1s\n",
      "[CV 3/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.845 total time=   3.1s\n",
      "[CV 4/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   2.9s\n",
      "[CV 5/5; 70/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 70/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.767 total time=   2.5s\n",
      "[CV 1/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   2.2s\n",
      "[CV 2/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   2.8s\n",
      "[CV 3/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   3.2s\n",
      "[CV 4/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.728 total time=   3.5s\n",
      "[CV 5/5; 71/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 71/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   2.9s\n",
      "[CV 1/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.923 total time=   3.3s\n",
      "[CV 2/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   2.8s\n",
      "[CV 3/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   3.0s\n",
      "[CV 4/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   2.5s\n",
      "[CV 5/5; 72/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 72/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.883 total time=   2.9s\n",
      "[CV 1/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.990 total time=   4.5s\n",
      "[CV 2/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.779 total time=   3.8s\n",
      "[CV 3/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   4.4s\n",
      "[CV 4/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.806 total time=   4.3s\n",
      "[CV 5/5; 73/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 73/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.738 total time=   4.6s\n",
      "[CV 1/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.962 total time=   4.2s\n",
      "[CV 2/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.777 total time=   4.0s\n",
      "[CV 4/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.757 total time=   3.1s\n",
      "[CV 5/5; 74/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 74/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.806 total time=   3.9s\n",
      "[CV 1/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   4.1s\n",
      "[CV 2/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   4.5s\n",
      "[CV 3/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.777 total time=   4.0s\n",
      "[CV 4/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.816 total time=   4.3s\n",
      "[CV 5/5; 75/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 75/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.825 total time=   3.1s\n",
      "[CV 1/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   4.5s\n",
      "[CV 2/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.788 total time=   4.0s\n",
      "[CV 3/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.845 total time=   4.2s\n",
      "[CV 4/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.845 total time=   4.0s\n",
      "[CV 5/5; 76/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 76/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.835 total time=   4.0s\n",
      "[CV 1/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   4.9s\n",
      "[CV 3/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   3.7s\n",
      "[CV 5/5; 77/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 77/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   4.0s\n",
      "[CV 1/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.817 total time=   4.5s\n",
      "[CV 3/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   3.2s\n",
      "[CV 4/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.709 total time=   3.9s\n",
      "[CV 5/5; 78/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 78/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   4.5s\n",
      "[CV 1/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   4.2s\n",
      "[CV 2/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   4.3s\n",
      "[CV 4/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   4.4s\n",
      "[CV 5/5; 79/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 79/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   4.6s\n",
      "[CV 1/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   4.4s\n",
      "[CV 2/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.837 total time=   3.8s\n",
      "[CV 3/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   4.2s\n",
      "[CV 4/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   3.9s\n",
      "[CV 5/5; 80/128] START activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 80/128] END activation_function=relu, batch_size=10, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   4.0s\n",
      "[CV 1/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.9s\n",
      "[CV 2/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.2s\n",
      "[CV 3/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   3.4s\n",
      "[CV 4/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.1s\n",
      "[CV 5/5; 81/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 81/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.0s\n",
      "[CV 1/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.4s\n",
      "[CV 3/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   3.1s\n",
      "[CV 5/5; 82/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 82/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.718 total time=   1.7s\n",
      "[CV 1/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   1.8s\n",
      "[CV 4/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   2.7s\n",
      "[CV 5/5; 83/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 83/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.709 total time=   3.4s\n",
      "[CV 1/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.990 total time=   2.3s\n",
      "[CV 2/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   2.7s\n",
      "[CV 3/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   3.9s\n",
      "[CV 4/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.689 total time=   2.7s\n",
      "[CV 5/5; 84/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 84/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   1.7s\n",
      "[CV 1/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   3.0s\n",
      "[CV 3/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   1.9s\n",
      "[CV 4/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   3.4s\n",
      "[CV 5/5; 85/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 85/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.1s\n",
      "[CV 1/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   3.1s\n",
      "[CV 4/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 86/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 86/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   3.4s\n",
      "[CV 1/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   1.8s\n",
      "[CV 3/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.3s\n",
      "[CV 5/5; 87/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 87/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   2.0s\n",
      "[CV 1/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   2.4s\n",
      "[CV 2/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   2.6s\n",
      "[CV 5/5; 88/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 88/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   3.4s\n",
      "[CV 1/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.5s\n",
      "[CV 2/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   4.7s\n",
      "[CV 3/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   4.0s\n",
      "[CV 4/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.728 total time=   2.9s\n",
      "[CV 5/5; 89/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 89/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   4.7s\n",
      "[CV 1/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   2.8s\n",
      "[CV 2/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   4.5s\n",
      "[CV 3/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   4.4s\n",
      "[CV 4/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.748 total time=   2.8s\n",
      "[CV 5/5; 90/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 90/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.786 total time=   4.4s\n",
      "[CV 1/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.990 total time=   2.8s\n",
      "[CV 2/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   4.4s\n",
      "[CV 3/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.738 total time=   3.6s\n",
      "[CV 5/5; 91/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 91/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.874 total time=   4.0s\n",
      "[CV 1/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.990 total time=   2.7s\n",
      "[CV 2/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.769 total time=   4.7s\n",
      "[CV 3/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.8s\n",
      "[CV 4/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.816 total time=   4.5s\n",
      "[CV 5/5; 92/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 92/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.854 total time=   3.3s\n",
      "[CV 1/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   4.3s\n",
      "[CV 3/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.2s\n",
      "[CV 4/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   4.8s\n",
      "[CV 5/5; 93/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 93/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   2.7s\n",
      "[CV 1/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   4.7s\n",
      "[CV 2/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.750 total time=   3.3s\n",
      "[CV 3/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   4.0s\n",
      "[CV 5/5; 94/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 94/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.699 total time=   2.8s\n",
      "[CV 1/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   4.6s\n",
      "[CV 2/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   3.1s\n",
      "[CV 3/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   4.8s\n",
      "[CV 4/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.9s\n",
      "[CV 5/5; 95/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 95/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   4.6s\n",
      "[CV 1/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   4.0s\n",
      "[CV 2/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   2.7s\n",
      "[CV 3/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   4.0s\n",
      "[CV 5/5; 96/128] START activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 96/128] END activation_function=relu, batch_size=10, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   3.9s\n",
      "[CV 1/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   3.1s\n",
      "[CV 2/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.534 total time=   2.9s\n",
      "[CV 4/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.1s\n",
      "[CV 5/5; 97/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 97/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.709 total time=   1.8s\n",
      "[CV 1/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   2.0s\n",
      "[CV 2/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   2.9s\n",
      "[CV 3/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.680 total time=   1.4s\n",
      "[CV 5/5; 98/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 98/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   1.5s\n",
      "[CV 1/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   2.3s\n",
      "[CV 3/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   1.4s\n",
      "[CV 4/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   2.9s\n",
      "[CV 5/5; 99/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 99/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.728 total time=   2.7s\n",
      "[CV 1/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   1.7s\n",
      "[CV 2/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   2.4s\n",
      "[CV 3/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   3.0s\n",
      "[CV 4/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.8s\n",
      "[CV 5/5; 100/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 100/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.709 total time=   1.5s\n",
      "[CV 1/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.837 total time=   2.2s\n",
      "[CV 3/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   2.1s\n",
      "[CV 4/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   2.1s\n",
      "[CV 5/5; 101/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 101/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.0s\n",
      "[CV 1/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.731 total time=   2.9s\n",
      "[CV 2/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.894 total time=   1.6s\n",
      "[CV 3/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.709 total time=   2.3s\n",
      "[CV 4/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   3.2s\n",
      "[CV 5/5; 102/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 102/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   2.6s\n",
      "[CV 1/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   2.9s\n",
      "[CV 3/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   3.1s\n",
      "[CV 4/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   2.1s\n",
      "[CV 5/5; 103/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 103/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   2.4s\n",
      "[CV 1/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.856 total time=   3.1s\n",
      "[CV 3/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.854 total time=   1.4s\n",
      "[CV 4/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.738 total time=   2.9s\n",
      "[CV 5/5; 104/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 104/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.748 total time=   2.7s\n",
      "[CV 1/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.971 total time=   2.7s\n",
      "[CV 2/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   1.9s\n",
      "[CV 3/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   3.2s\n",
      "[CV 4/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   3.2s\n",
      "[CV 5/5; 105/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 105/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   2.5s\n",
      "[CV 1/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.981 total time=   3.5s\n",
      "[CV 2/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.0s\n",
      "[CV 3/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.709 total time=   2.5s\n",
      "[CV 4/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.738 total time=   3.6s\n",
      "[CV 5/5; 106/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 106/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.748 total time=   3.7s\n",
      "[CV 1/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.990 total time=   3.6s\n",
      "[CV 2/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.2s\n",
      "[CV 3/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   2.6s\n",
      "[CV 4/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.816 total time=   3.5s\n",
      "[CV 5/5; 107/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 107/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.835 total time=   3.5s\n",
      "[CV 1/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   4.0s\n",
      "[CV 3/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.650 total time=   3.6s\n",
      "[CV 4/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.718 total time=   3.3s\n",
      "[CV 5/5; 108/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 108/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.709 total time=   2.1s\n",
      "[CV 1/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.990 total time=   3.4s\n",
      "[CV 2/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.885 total time=   3.6s\n",
      "[CV 3/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.913 total time=   3.1s\n",
      "[CV 5/5; 109/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 109/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.699 total time=   3.6s\n",
      "[CV 1/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.933 total time=   3.4s\n",
      "[CV 2/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.971 total time=   3.9s\n",
      "[CV 3/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.854 total time=   3.5s\n",
      "[CV 4/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.854 total time=   3.7s\n",
      "[CV 5/5; 110/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 110/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.913 total time=   3.2s\n",
      "[CV 1/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.635 total time=   2.7s\n",
      "[CV 2/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   2.1s\n",
      "[CV 3/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   3.6s\n",
      "[CV 4/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   4.0s\n",
      "[CV 5/5; 111/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 111/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   2.9s\n",
      "[CV 1/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.990 total time=   4.0s\n",
      "[CV 2/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   3.3s\n",
      "[CV 4/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.883 total time=   3.6s\n",
      "[CV 5/5; 112/128] START activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 112/128] END activation_function=relu, batch_size=20, dropout_rate=0.0, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   3.7s\n",
      "[CV 1/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   2.7s\n",
      "[CV 2/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.0s\n",
      "[CV 3/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.680 total time=   1.5s\n",
      "[CV 5/5; 113/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 113/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.2s\n",
      "[CV 1/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.3s\n",
      "[CV 2/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.2s\n",
      "[CV 3/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   3.1s\n",
      "[CV 4/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.689 total time=   2.6s\n",
      "[CV 5/5; 114/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 114/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.699 total time=   3.2s\n",
      "[CV 1/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 1/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   2.8s\n",
      "[CV 3/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   2.9s\n",
      "[CV 4/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.680 total time=   3.7s\n",
      "[CV 5/5; 115/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 115/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   3.2s\n",
      "[CV 1/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   2.6s\n",
      "[CV 3/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.524 total time=   1.3s\n",
      "[CV 4/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   2.4s\n",
      "[CV 5/5; 116/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 116/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.699 total time=   2.9s\n",
      "[CV 1/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.2s\n",
      "[CV 2/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   2.9s\n",
      "[CV 3/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.680 total time=   3.2s\n",
      "[CV 5/5; 117/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 117/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.767 total time=   3.2s\n",
      "[CV 1/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.798 total time=   2.6s\n",
      "[CV 3/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   2.8s\n",
      "[CV 4/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.825 total time=   3.1s\n",
      "[CV 5/5; 118/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 118/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.854 total time=   3.2s\n",
      "[CV 1/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   2.7s\n",
      "[CV 2/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   2.2s\n",
      "[CV 3/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.524 total time=   3.0s\n",
      "[CV 4/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.680 total time=   3.0s\n",
      "[CV 5/5; 119/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 119/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.699 total time=   3.1s\n",
      "[CV 1/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   2.9s\n",
      "[CV 2/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 2/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.769 total time=   2.8s\n",
      "[CV 3/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.524 total time=   2.7s\n",
      "[CV 4/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.680 total time=   3.2s\n",
      "[CV 5/5; 120/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 120/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.738 total time=   3.1s\n",
      "[CV 1/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 1/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=1.000 total time=   4.3s\n",
      "[CV 2/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 2/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.750 total time=   3.8s\n",
      "[CV 3/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 3/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.524 total time=   3.7s\n",
      "[CV 4/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 4/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.699 total time=   3.3s\n",
      "[CV 5/5; 121/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
      "[CV 5/5; 121/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.748 total time=   2.0s\n",
      "[CV 1/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 1/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=1.000 total time=   3.4s\n",
      "[CV 2/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 2/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.750 total time=   3.5s\n",
      "[CV 3/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 3/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.524 total time=   3.5s\n",
      "[CV 4/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 4/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.748 total time=   3.2s\n",
      "[CV 5/5; 122/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
      "[CV 5/5; 122/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.738 total time=   4.1s\n",
      "[CV 1/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 2/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   3.8s\n",
      "[CV 3/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 3/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.524 total time=   3.6s\n",
      "[CV 4/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 4/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.709 total time=   3.2s\n",
      "[CV 5/5; 123/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
      "[CV 5/5; 123/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.699 total time=   3.7s\n",
      "[CV 1/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 1/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=1.000 total time=   2.5s\n",
      "[CV 2/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 2/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.750 total time=   2.0s\n",
      "[CV 3/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 3/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.680 total time=   3.7s\n",
      "[CV 4/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 4/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.738 total time=   4.0s\n",
      "[CV 5/5; 124/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
      "[CV 5/5; 124/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.757 total time=   3.7s\n",
      "[CV 1/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 1/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   3.6s\n",
      "[CV 2/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 2/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.875 total time=   3.3s\n",
      "[CV 3/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 3/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.524 total time=   3.4s\n",
      "[CV 4/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 4/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.709 total time=   3.9s\n",
      "[CV 5/5; 125/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
      "[CV 5/5; 125/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.893 total time=   3.2s\n",
      "[CV 1/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 1/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   3.0s\n",
      "[CV 2/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 2/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.788 total time=   3.8s\n",
      "[CV 3/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 3/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.524 total time=   2.2s\n",
      "[CV 4/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 4/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.680 total time=   3.7s\n",
      "[CV 5/5; 126/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
      "[CV 5/5; 126/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.864 total time=   3.8s\n",
      "[CV 1/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 1/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   3.7s\n",
      "[CV 2/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 2/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.769 total time=   3.3s\n",
      "[CV 3/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 3/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.641 total time=   3.5s\n",
      "[CV 4/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 4/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.777 total time=   3.7s\n",
      "[CV 5/5; 127/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
      "[CV 5/5; 127/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.893 total time=   3.4s\n",
      "[CV 1/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 1/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   3.8s\n",
      "[CV 2/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.837 total time=   3.6s\n",
      "[CV 3/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 3/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.786 total time=   3.7s\n",
      "[CV 4/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 4/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.854 total time=   2.5s\n",
      "[CV 5/5; 128/128] START activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
      "[CV 5/5; 128/128] END activation_function=relu, batch_size=20, dropout_rate=0.1, epochs=30, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.699 total time=   2.4s\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9050410747528076, using {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7208737850189209,0.16794994181639633 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7498693108558655,0.15877935783472175 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7871172547340393,0.041620472501260226 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7327109932899475,0.11676909784335547 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7733569860458374,0.11406334161390046 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7364077568054199,0.15359763543603858 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8023898363113403,0.09913046953700094 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7736370325088501,0.033583226080114284 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7598020911216736,0.1041070515066714 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7810492873191833,0.12922859243222967 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.650970870256424,0.232809376585483 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7075056076049805,0.15391477228427364 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.6977595210075378,0.1256540737285449 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7210418224334717,0.12205390332685807 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7189507126808167,0.15840973974428235 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7538834929466247,0.1507170152832545 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7966206192970275,0.09078047996186933 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7694174647331238,0.12278771769944807 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7657020092010498,0.07870406949937182 with: {'activation_function': 'softmax', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.6208737850189209,0.2497637683090065 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.6587378680706024,0.22758449693740784 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8237490773200988,0.08386080472456076 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8140403270721436,0.08002370671443965 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7597460746765137,0.11272381277306141 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7191187500953674,0.09941607949677234 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8722927451133728,0.04902561660443719 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8489544510841369,0.09121377782334873 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7830470561981201,0.10827894094530836 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8120985865592957,0.09136573902165468 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.6587378680706024,0.22758449693740784 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.5305825233459472,0.2757845556417363 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.650970870256424,0.232809376585483 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7829723596572876,0.09704524742495302 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7850261449813842,0.10545303110279365 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7175690770149231,0.04901099547735884 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7655526399612427,0.11661111152098728 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7851381659507751,0.06991557183633142 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8296489834785461,0.03653782266282621 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7945668458938598,0.10489741958367704 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8024458527565003,0.09478662276158532 with: {'activation_function': 'softmax', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7461725234985351,0.12097307860028224 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7575055956840515,0.1666405573255901 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7717139720916748,0.05723040577904709 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7402912616729737,0.15235295838878546 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.752091109752655,0.14398780362403144 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7674383878707886,0.14920678566771728 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8102688431739807,0.07806299542924741 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8334951400756836,0.08753492227012609 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.862546694278717,0.07180998004202488 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7459858059883118,0.1578353872353606 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.769249427318573,0.1594743729640207 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7344660282135009,0.1532597362499129 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.734466016292572,0.1537509780062806 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7325242638587952,0.15400213076804797 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7306012034416198,0.15042370212121212 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7402912616729737,0.15358536146170676 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7402912616729737,0.15235295838878546 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7616504907608033,0.15106683729307338 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.775261390209198,0.15557482809292195 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8218259930610656,0.10247129513972567 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 10, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.734466016292572,0.15140339696325283 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7364077568054199,0.15359763543603858 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7325242638587952,0.15400213076804797 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7478902101516723,0.16029497525300973 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7968446493148804,0.06815530529217644 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.781067955493927,0.11483840736129396 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8391150116920472,0.09489546351955998 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7248132944107055,0.14439039302604334 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.784988796710968,0.09898392676198002 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7830283880233765,0.151522313240816 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.765533983707428,0.12156874803922754 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8021844744682312,0.16869316128281905 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.9050410747528076,0.04544949710738374 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.6882748246192932,0.12364304717157035 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7694361567497253,0.1595419295221316 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.0, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7325242757797241,0.15375710605921813 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7441747546195984,0.15396540272278342 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.8003920793533326,0.15467522000175618 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7421956658363342,0.15402615923749535 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 10, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n",
      "0.7441747665405274,0.15224155265065867 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 2}\n",
      "0.7519417524337768,0.15072326914723128 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 4, 'neuron2': 4}\n",
      "0.7364077687263488,0.15285944434968482 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 2}\n",
      "0.7849514484405518,0.11094756086727434 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.001, 'neuron1': 8, 'neuron2': 4}\n",
      "0.8002427101135254,0.16653315523399168 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 2}\n",
      "0.771284544467926,0.16163884111759327 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 4, 'neuron2': 4}\n",
      "0.8159820675849915,0.12186186304600276 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 2}\n",
      "0.8352688550949097,0.09843925869186021 with: {'activation_function': 'relu', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 30, 'init': 'normal', 'learning_rate': 0.1, 'neuron1': 8, 'neuron2': 4}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(8,input_dim = 28,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model1.add(Dropout(0.0))\n",
    "    model1.add(Dense(4,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model1.add(Dropout(0.0))\n",
    "    model1.add(Dense(1,activation = 'sigmoid'))\n",
    "    adam = Adam(lr = 0.1)\n",
    "    model1.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 20,epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x279ffe04888>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_standardized,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model1.predict(X_standardized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9226305609284333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y,Y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
